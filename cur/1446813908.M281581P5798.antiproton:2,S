Return-Path: <cypherpunks-bounces@cpunks.org>
Received: from antiproton.jfet.org (localhost.localdomain [127.0.0.1])
	by antiproton.jfet.org (8.14.4/8.14.4/Debian-8) with ESMTP id tA6Cigke005778;
	Fri, 6 Nov 2015 07:44:42 -0500
Received: from mx1.allurbase.net (mx1.allurbase.net [91.108.68.209])
 by antiproton.jfet.org (8.14.4/8.14.4/Debian-8) with ESMTP id tA6CiXeF005772
 for <cypherpunks@cpunks.org>; Fri, 6 Nov 2015 07:44:34 -0500
Date: Fri, 6 Nov 2015 12:43:25 +0000
From: Cubed <chasintail@emailcontrol.org>
To: cypherpunks@cpunks.org
Subject: Re: Facebook censorship
Message-ID: <20151106124325.258dfde9@emailcontrol.org>
In-Reply-To: <20151103164028.GA2617@sivokote.iziade.m$>
References: <CAOsGNSTjOUT-_qEV3EEYF-+0y3khwcc4xFyzBzGh17=Q7oyxPw@mail.gmail.com>
 <56380CC2.2070506@openmailbox.org>
 <20151103035136.50a9ff16@emailcontrol.org>
 <20151103164028.GA2617@sivokote.iziade.m$>
X-Mailer: Claws Mail 3.8.1 (GTK+ 2.24.10; i486-pc-linux-gnu)
Mime-Version: 1.0
Content-Type: text/plain; charset=US-ASCII
Content-Transfer-Encoding: 7bit
X-BeenThere: cypherpunks@cpunks.org
X-Mailman-Version: 2.1.18
Precedence: list
List-Id: The Cypherpunks Mailing List <cypherpunks.cpunks.org>
List-Unsubscribe: <https://cpunks.org/mailman/options/cypherpunks>,
 <mailto:cypherpunks-request@cpunks.org?subject=unsubscribe>
List-Archive: <http://cpunks.org/pipermail/cypherpunks/>
List-Post: <mailto:cypherpunks@cpunks.org>
List-Help: <mailto:cypherpunks-request@cpunks.org?subject=help>
List-Subscribe: <https://cpunks.org/mailman/listinfo/cypherpunks>,
 <mailto:cypherpunks-request@cpunks.org?subject=subscribe>
Errors-To: cypherpunks-bounces@cpunks.org
Sender: "cypherpunks" <cypherpunks-bounces@cpunks.org>
Lines: 59

Singularity defined as the moment when the technology humans create
creates technology faster than humans can understand it. Robots
creating robots in ways we didn't dictate and couldn't predict. 

As I've used the idea, I don't see it as a necessarily negative "event"
or "period". It simply is, or would be I should say. 

Imagine we somehow travel very far in space and find an less evolved
species of sentient beings living on a planet rich with resources. What
do you think those sentient beings will think when we start digging up
precious metals and maybe even mining fossil fuels, if we are still
doing that in this theoretical future? Will they understand our
machines? Will they understand our.. anything? Will we be seen as a
danger or as a deity? Most importantly, will they understand our
motivations or simply view our motivations through the lenses of their
existence? 

Assuming all sentient life evolves along the same basic trajectory as
ours, they will probably seek some answers to these many questions
through experiences they can relate to. But their experiences will
never provide meaningful frames of reference. 

Now, think about strong AI and the thoughts it would have. Strong AI
will be motivated, very quickly by some people's predictions, by things
we will not understand, eventually. 

To think that this conceptual future will be controllably is false by
the very definition of singularity. Are we controlled by the cows we
eat? Is our existence dictated by dolphins? We will not be able to
control strong AI, at a point, anymore than we can control the sun and
the moon. Which is not to say we will be without control, you can
always wear sunglasses. I'm sure many many humans will wear sunglasses.

In regards to extraterrestrial beings as well as strong AI; the
singularity idea is more than just bots and our deaths. It's about
transcending biology. And that's exactly where the hacker ethos is most
important because it's humans with disabilities and hackers that will
being the transformation of man to machine. There are no absolutes; the
singularity is not a this or that event. It's a technological awakening
and it's precisely when we, as humans, will have the opportunity to not
only shed our biology, but discard our dated concepts of society. 



On Tue, 3 Nov 2015 18:40:28 +0200
Georgi Guninski <guninski@guninski.com> wrote:

> On Tue, Nov 03, 2015 at 03:51:36AM +0000, Cubed wrote:
> > What we see here is the first signs of singularity. Before long,
> > these
> 
> By "singularity" do you mean "technological singularity" as defined in
> wikipedia (strong AI screws humans)?
> 
> I don't think such human made singularity will ever happen for the
> simple reason "hacker oligarchs" will control the bots.
> Extraterrestrial stuff maybe be possible though.

