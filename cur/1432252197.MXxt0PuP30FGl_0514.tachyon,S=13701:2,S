From cypherpunks-bounces@cpunks.org  Sun Jan 12 21:55:09 2014
Return-Path: <cypherpunks-bounces@cpunks.org>
Received: from antiproton.jfet.org (localhost.localdomain [127.0.0.1])
	by antiproton.jfet.org (8.14.4/8.14.4/Debian-4) with ESMTP id s0D2sc8L009762;
	Sun, 12 Jan 2014 21:54:42 -0500
Received: from mx1.riseup.net (mx1.riseup.net [198.252.153.129])
 by antiproton.jfet.org (8.14.4/8.14.4/Debian-4) with ESMTP id s0D2sYAi009756
 (version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NOT)
 for <cypherpunks@cpunks.org>; Sun, 12 Jan 2014 21:54:36 -0500
Received: from fulvetta.riseup.net (fulvetta-pn.riseup.net [10.0.1.75])
 (using TLSv1 with cipher DHE-RSA-AES256-SHA (256/256 bits))
 (Client CN "*.riseup.net", Issuer "Gandi Standard SSL CA" (not verified))
 by mx1.riseup.net (Postfix) with ESMTPS id 7C17B50F9A;
 Sun, 12 Jan 2014 18:54:31 -0800 (PST)
Received: from [127.0.0.1] (localhost [127.0.0.1])
 (Authenticated sender: jessetaylor84@fulvetta.riseup.net)
 with ESMTPSA id 5CF0C1DB
Message-ID: <52D35517.8050003@riseup.net>
Date: Sun, 12 Jan 2014 18:53:11 -0800
From: Jesse Taylor <jessetaylor84@riseup.net>
User-Agent: Mozilla/5.0 (X11; Linux x86_64;
 rv:17.0) Gecko/20131103 Icedove/17.0.10
MIME-Version: 1.0
To: coderman@gmail.com, cathalgarvey@cathalgarvey.me
Subject: Re: Replacing corporate search engines with anonymous/decentralized
 search
X-Enigmail-Version: 1.6
Content-Type: multipart/alternative;
 boundary="------------080604070805060806000702"
X-Virus-Scanned: clamav-milter 0.97.8 at mx1
X-Virus-Status: Clean
Cc: cypherpunks@cpunks.org
X-BeenThere: cypherpunks@cpunks.org
X-Mailman-Version: 2.1.15
Precedence: list
List-Id: The Cypherpunks Mailing List <cypherpunks.cpunks.org>
List-Unsubscribe: <https://cpunks.org/mailman/options/cypherpunks>,
 <mailto:cypherpunks-request@cpunks.org?subject=unsubscribe>
List-Archive: <http://cpunks.org/pipermail/cypherpunks/>
List-Post: <mailto:cypherpunks@cpunks.org>
List-Help: <mailto:cypherpunks-request@cpunks.org?subject=help>
List-Subscribe: <https://cpunks.org/mailman/listinfo/cypherpunks>,
 <mailto:cypherpunks-request@cpunks.org?subject=subscribe>
Errors-To: cypherpunks-bounces@cpunks.org
Sender: "cypherpunks" <cypherpunks-bounces@cpunks.org>

This is a multi-part message in MIME format.
--------------080604070805060806000702
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

Thanks for your comments on this folks ... lots of food for thought.

coderman@gmail.com <mailto:coderman@gmail.com> said:

    /the longer discussion is how to make decentralized search useful.
    "Google style" search has a terrific performance advantage over
    decentralized designs by brute force. however, take advantage of
    massive endpoint / peer processing and resources combined with
    implicit observational metrics for reputation and recommendation,
    inside a well integrated framework for resource discovery in usable
    software, and you have something more robust and more effective than
    "Google style" could ever provide./

Yes, it does seem like the speed advantage of centralized search will be
a barrier to adoption of decentralized search. This is analogous to the
difficulty getting people adopt systems like Tor because it is slow. But
I think that as more people become aware of the extent of
state/corporate surveillance, they will become more inclined to accept
solutions that are slower in exchange for not having their search habits
monitored, and also being able to receive uncensored search results. As
long as decentralized search is (a) usable/simple and (b) provides
quality results, I feel like speed is somewhat of a secondary concern.
The key question to me is: "How do we build a search engine that is
simple enough for Grandma to use
<http://freehaven.net/anonbib/cache/usability:weis2006.pdf>, that
produces quality results without massive centralized indexing servers?"

Standalone P2P search applications (e.g. Yacy) don't really make sense
from a usability perspective. It's unrealistic to expect hundreds of
millions of users to download a standalone Java app, and configure a P2P
search node. What would make more sense, and would lead to much more
rapid/widespread adoption, is to use protocols like WebSockets
<http://mikemp.mit.edu/wss/wss-mikemp.pdf> / WebRTC
<http://inet.cpt.haw-hamburg.de/papers/vws-lwpcd-13.pdf> to facilitate
P2P connectivity in the web browser
<http://inet.cpt.haw-hamburg.de/teaching/ws-2012-13/master-projekt/maxjonas-werner_aw1.pdf>,
so that everything can be done via a simple browser plugin that can be
installed by anyone with few clicks, and would then just allow people to
use the browser search bar as usual. This browser integration would also
have the bonus of simplifying the choice of what to index -- it could
just default to indexing bookmarked and frequently-visited pages, and
then be optionally customized by more advanced users to create custom
indexes (i.e. all of the complexity of setting up indexing could be
hidden from the user, unless they choose to look for it).

To help bootstrap the WebRTC nodes into the P2P network, and to deal
with some of the instability inherent in P2P networks (i.e. by creating
stable "super-peer
<http://infolab.stanford.edu/%7Ebyang/pubs/superpeer.pdf>" indexing
nodes), I like cathalgarvey's suggestion of utilizing something like a
Wordpress//plugin that would use the same index/search standard as the
WebRTC clients, but could additionally bootstrap the web-based clients.
As cathalgarvey said:/
/

    /A standard rather than a codebase. But there's a huge advantage to
    this line of thought, if you'll bear with me. A two-digit fraction
    of the web right now is powered by Wordpress.org, who explicitly
    advocate open/free culture. If you can convince them to include a
    social search/index standard of this type, which is virtually free
    in terms of computer resources, then you'd have it deployed across
    the web in days as the next update rolled out. Indeed, even if
    Wordpress seemed reluctant, a wordpress plugin could probably be
    written quickly enough to enable such a thing and make it available
    for casual use. Suddenly, a bunch of PHP-powered sites around the
    web start committing small bits and pieces of resources to a social
    search engine based on human-curated attestations of trust that flow
    through a web, helping to confine spammers to the fringes and to
    users with stupid taste. /

What would also be interesting is if this standard enabled some kind of
"pingback" mechanism whereby WebRTC nodes could be associated with
specific super-peer nodes (e.g. maybe people who have bookmarked the
super-peer site in their browser, or subscribe to its feed), so that in
addition to broad/random queries that target the entire P2P network,
clients could also create more targeted custom searches that say
something like "start the search with the nodes that are clustered
around these super-peers". This would create an enormous diversity of
search possibilities -- hundreds of thousands (millions) of different
"search engines", each of which would return different results for the
same query, depending on where you start your search ... This diversity
is another reason I find P2P search interesting, in addition to the
benefits re: censorship, traffic shaping, and surveillance.

I've been looking around for some kind of WebRTC P2P search engine and
haven't found anything yet ... maybe I've found a programming project
for this summer :)

-- Jesse Taylor <http://www.interference.cc>

--------------080604070805060806000702
Content-Type: text/html; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

<html>
  <head>
    <meta http-equiv="content-type" content="text/html;
      charset=ISO-8859-1">
  </head>
  <body bgcolor="#FFFFFF" text="#000000">
    Thanks for your comments on this folks ... lots of food for thought.<br>
    <br>
    <a href="mailto:coderman@gmail.com">coderman@gmail.com</a> said:<br>
    <blockquote><i>the longer discussion is how to make decentralized
        search useful. "Google style" search has a terrific performance
        advantage over decentralized designs by brute force. however,
        take advantage of massive endpoint / peer processing and
        resources combined with implicit observational metrics for
        reputation and recommendation, inside a well integrated
        framework for resource discovery in usable software, and you
        have something more robust and more effective than "Google
        style" could ever provide.</i><br>
      <br>
    </blockquote>
    Yes, it does seem like the speed advantage of centralized search
    will be a barrier to adoption of decentralized search. This is
    analogous to the difficulty getting people adopt systems like Tor
    because it is slow. But I think that as more people become aware of
    the extent of state/corporate surveillance, they will become more
    inclined to accept solutions that are slower in exchange for not
    having their search habits monitored, and also being able to receive
    uncensored search results. As long as decentralized search is (a)
    usable/simple and (b) provides quality results, I feel like speed is
    somewhat of a secondary concern. The key question to me is: "How do
    we build a search engine that is <a
      href="http://freehaven.net/anonbib/cache/usability:weis2006.pdf">simple





      enough for Grandma to use</a>, that produces quality results
    without massive centralized indexing servers?"<br>
    <br>
    Standalone P2P search applications (e.g. Yacy) don't really make
    sense from a usability perspective. It's unrealistic to expect
    hundreds of millions of users to download a standalone Java app, and
    configure a P2P search node. What would make more sense, and would
    lead to much more rapid/widespread adoption, is to use protocols
    like <a href="http://mikemp.mit.edu/wss/wss-mikemp.pdf">WebSockets</a>
    / <a href="http://inet.cpt.haw-hamburg.de/papers/vws-lwpcd-13.pdf">WebRTC</a>
    to facilitate <a
href="http://inet.cpt.haw-hamburg.de/teaching/ws-2012-13/master-projekt/maxjonas-werner_aw1.pdf">P2P
      connectivity in the web browser</a>, so that everything can be
    done via a simple browser plugin that can be installed by anyone
    with few clicks, and would then just allow people to use the browser
    search bar as usual. This browser integration would also have the
    bonus of simplifying the choice of what to index -- it could just
    default to indexing bookmarked and frequently-visited pages, and
    then be optionally customized by more advanced users to create
    custom indexes (i.e. all of the complexity of setting up indexing
    could be hidden from the user, unless they choose to look for it). <br>
    <br>
    To help bootstrap the WebRTC nodes into the P2P network, and to deal
    with some of the instability inherent in P2P networks (i.e. by
    creating stable "<a
      href="http://infolab.stanford.edu/%7Ebyang/pubs/superpeer.pdf">super-peer</a>"
    indexing nodes), I like cathalgarvey's suggestion of utilizing
    something like a Wordpress<i> </i>plugin that would use the same
    index/search standard as the WebRTC clients, but could additionally
    bootstrap the web-based clients. As cathalgarvey said:<i><br>
    </i>
    <blockquote><i>A standard rather than a codebase. But there's a huge
        advantage to this line of thought, if you'll bear with me. A
        two-digit fraction of the web right now is powered by
        Wordpress.org, who explicitly advocate open/free culture. If you
        can convince them to include a social search/index standard of
        this type, which is virtually free in terms of computer
        resources, then you'd have it deployed across the web in days as
        the next update rolled out. Indeed, even if Wordpress seemed
        reluctant, a wordpress plugin could probably be written quickly
        enough to enable such a thing and make it available for casual
        use. Suddenly, a bunch of PHP-powered sites around the web start
        committing small bits and pieces of resources to a social search
        engine based on human-curated attestations of trust that flow
        through a web, helping to confine spammers to the fringes and to
        users with stupid taste. </i></blockquote>
    What would also be interesting is if this standard enabled some kind
    of "pingback" mechanism whereby WebRTC nodes could be associated
    with specific super-peer nodes (e.g. maybe people who have
    bookmarked the super-peer site in their browser, or subscribe to its
    feed), so that in addition to broad/random queries that target the
    entire P2P network, clients could also create more targeted custom
    searches that say something like "start the search with the nodes
    that are clustered around these super-peers". This would create an
    enormous diversity of search possibilities -- hundreds of thousands
    (millions) of different "search engines", each of which would return
    different results for the same query, depending on where you start
    your search ... This diversity is another reason I find P2P search
    interesting, in addition to the benefits re: censorship, traffic
    shaping, and surveillance.<br>
    <br>
    I've been looking around for some kind of WebRTC P2P search engine
    and haven't found anything yet ... maybe I've found a programming
    project for this summer :)<br>
    <br>
    -- <a href="http://www.interference.cc">Jesse Taylor</a><br>
  </body>
</html>

--------------080604070805060806000702--

