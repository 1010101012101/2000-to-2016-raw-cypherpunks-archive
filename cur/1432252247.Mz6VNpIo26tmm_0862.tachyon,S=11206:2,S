From rswatjfet.org+caf_=rsw=jfet.org@gmail.com  Mon Nov  3 11:13:07 2014
Return-Path: <rswatjfet.org+caf_=rsw=jfet.org@gmail.com>
Received: from mail-pa0-f52.google.com (mail-pa0-f52.google.com [209.85.220.52])
	by antiproton.jfet.org (8.14.4/8.14.4/Debian-4.1) with ESMTP id sA3GD5xF031055
	(version=TLSv1/SSLv3 cipher=RC4-SHA bits=128 verify=NOT)
	for <rsw@jfet.org>; Mon, 3 Nov 2014 11:13:07 -0500
Received: by mail-pa0-f52.google.com with SMTP id fa1so12424076pad.39
        for <rsw@jfet.org>; Mon, 03 Nov 2014 08:12:43 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-original-authentication-results:delivered-to:date:message-id:to
         :subject:in-reply-to:user-agent:accept-language:content-type
         :mime-version:content-disposition:content-transfer-encoding
         :precedence:list-id:list-unsubscribe:list-archive:list-post
         :list-help:list-subscribe:reply-to:errors-to:sender:from;
        bh=3IZIK/qZKZc4w3Z+64b/TYW8QOXKNzqEwVjnrsJqnNE=;
        b=dJA5dQvsE4CBBrACa3CtLQA83gUlSSEH5U7/KPGNhuLj9Lmpewlh/4mcFCThu7JPms
         kdSC09I+qHRXWa0Q2M5tMpqPntVERGZSNKPMoFVLsumVYyFHi+ENJYcZ2YryKoYGF5mK
         okco2WdIE/kLdv6pO6xsdrZeSqHYoo4kwxU4WqyVp90WPSQ/E8LQY3GgRC60w2cryveP
         D/923jhbkIAHA5X8h62NlOkRaFVmdM/XTvFVWZYx46dmZEb9zXibFDEA+vSZV9LnXajI
         IgIn++6Ax9iaQQrrcpPGYGnyCCvDXHOqfWqKsgqnMCSPp/YhZldmljGRHD5QEG4L5ooe
         6KOQ==
X-Original-Authentication-Results: mx.google.com;       spf=neutral (google.com: 209.141.47.85 is neither permitted nor denied by domain of rsw+cypherpunks-bounces=cpunks.org@gloop.phonon.net) smtp.mail=rsw+cypherpunks-bounces=cpunks.org@gloop.phonon.net
X-Received: by 10.70.38.134 with SMTP id g6mr2448106pdk.124.1415031163559;
        Mon, 03 Nov 2014 08:12:43 -0800 (PST)
X-Forwarded-To: rsw@jfet.org
X-Forwarded-For: rswatjfet.org@gmail.com rsw@jfet.org
Delivered-To: rswatjfet.org@gmail.com
Received: by 10.70.135.1 with SMTP id po1csp287994pdb;
        Mon, 3 Nov 2014 08:12:42 -0800 (PST)
X-Received: by 10.70.42.145 with SMTP id o17mr32968457pdl.34.1415031162695;
        Mon, 03 Nov 2014 08:12:42 -0800 (PST)
Received: from localhost (antiproton.jfet.org. [209.141.47.85])
        by mx.google.com with ESMTPS id lr3si15617339pab.140.2014.11.03.08.12.42
        for <rswATjfet.org@gmail.com>
        (version=TLSv1.2 cipher=RC4-SHA bits=128/128);
        Mon, 03 Nov 2014 08:12:42 -0800 (PST)
Received-SPF: neutral (google.com: 209.141.47.85 is neither permitted nor denied by domain of rsw+cypherpunks-bounces=cpunks.org@gloop.phonon.net) client-ip=209.141.47.85;
Authentication-Results: mx.google.com;
       spf=neutral (google.com: 209.141.47.85 is neither permitted nor denied by domain of rsw+cypherpunks-bounces=cpunks.org@gloop.phonon.net) smtp.mail=rsw+cypherpunks-bounces=cpunks.org@gloop.phonon.net
Received: from antiproton.jfet.org (localhost.localdomain [127.0.0.1])
	by antiproton.jfet.org (8.14.4/8.14.4/Debian-4.1) with ESMTP id sA3GC2E5031035;
	Mon, 3 Nov 2014 11:12:08 -0500
Received: from mail.cheiraminhavirilha.com
 (37.58.112.178-static.reverse.softlayer.com [37.58.112.178])
 by antiproton.jfet.org (8.14.4/8.14.4/Debian-4.1) with ESMTP id sA3GBumN031031
 (version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-GCM-SHA384 bits=256 verify=NOT)
 for <cypherpunks@cpunks.org>; Mon, 3 Nov 2014 11:11:59 -0500
Received: from localhost.localdomain ([127.0.0.1]:57780 helo=server1.xyz.com)
 by server1.xyz.com with esmtps (TLSv1:AES256-SHA:256) (Exim 4.72)
 (envelope-from <cypherpunks@cheiraminhavirilha.com>)
 id 1XlKEJ-0004bg-VV; Mon, 03 Nov 2014 10:11:44 -0600
Received: from 127.0.0.1 ([127.0.0.1]) by 127.0.0.1 (Horde Framework) with
 HTTP; Mon, 03 Nov 2014 16:11:43 +0000
Date: Mon, 03 Nov 2014 16:11:43 +0000
Message-ID: <20141103161143.Horde.xmsthx3wcxD8NcGsgLU7xw1@127.0.0.1>
To: cypherpunks@cpunks.org
Subject: Re: Brain decoder can eavesdrop on your inner voice
In-Reply-To: <20141103124015.GC10467@leitl.org>
User-Agent: Internet Messaging Program (IMP) H5 (6.2.0)
Accept-Language: en
Content-Type: text/plain; charset=UTF-8; format=flowed; DelSp=Yes
MIME-Version: 1.0
Content-Disposition: inline
Content-Transfer-Encoding: 8bit
X-MIME-Autoconverted: from quoted-printable to 8bit by antiproton.jfet.org id
 sA3GBumN031031
X-BeenThere: cypherpunks@cpunks.org
X-Mailman-Version: 2.1.18
Precedence: list
List-Id: The Cypherpunks Mailing List <cypherpunks.cpunks.org>
List-Unsubscribe: <https://cpunks.org/mailman/options/cypherpunks>,
 <mailto:cypherpunks-request@cpunks.org?subject=unsubscribe>
List-Archive: <http://cpunks.org/pipermail/cypherpunks/>
List-Post: <mailto:cypherpunks@cpunks.org>
List-Help: <mailto:cypherpunks-request@cpunks.org?subject=help>
List-Subscribe: <https://cpunks.org/mailman/listinfo/cypherpunks>,
 <mailto:cypherpunks-request@cpunks.org?subject=subscribe>
Reply-To: cypherpunks@cheiraminhavirilha.com
Errors-To: cypherpunks-bounces@cpunks.org
Sender: "cypherpunks" <cypherpunks-bounces@cpunks.org>
From: Virilha <cypherpunks@cheiraminhavirilha.com>
X-Gspam-Loop: antiproton.jfet.org
Status: O
Content-Length: 6077
Lines: 122


Maybe I will start to wear a hat sooner than I thought.

https://en.wikipedia.org/wiki/Tin_foil_hat

----- Message from Eugen Leitl <eugen@leitl.org> ---------
    Date: Mon, 3 Nov 2014 13:40:15 +0100
    From: Eugen Leitl <eugen@leitl.org>
Subject: Brain decoder can eavesdrop on your inner voice
      To: tt@postbiota.org, neuro@postbiota.org, cypherpunks@cpunks.org


> http://www.newscientist.com/article/mg22429934.000-brain-decoder-can-eavesdrop-on-your-inner-voice.html
>
> Brain decoder can eavesdrop on your inner voice
>
> 29 October 2014 by Helen Thomson
>
> Magazine issue 2993. Subscribe and save
>
> For similar stories, visit the The Human Brain Topic Guide
>
> As you read this, your neurons are firing – that brain activity can now
> be decoded to reveal the silent words in your head
>
> TALKING to yourself used to be a strictly private pastime. That's no longer
> the case – researchers have eavesdropped on our internal monologue for
> the first time. The achievement is a step towards helping people who cannot
> physically speak communicate with the outside world.
>
> "If you're reading text in a newspaper or a book, you hear a voice in your
> own head," says Brian Pasley at the University of California, Berkeley.
> "We're trying to decode the brain activity related to that voice to create a
> medical prosthesis that can allow someone who is paralysed or locked in to
> speak."
>
> When you hear someone speak, sound waves activate sensory neurons in your
> inner ear. These neurons pass information to areas of the brain where
> different aspects of the sound are extracted and interpreted as words.
>
> In a previous study, Pasley and his colleagues recorded brain activity in
> people who already had electrodes implanted in their brain to treat epilepsy,
> while they listened to speech. The team found that certain neurons in the
> brain's temporal lobe were only active in response to certain aspects of
> sound, such as a specific frequency. One set of neurons might only react to
> sound waves that had a frequency of 1000 hertz, for example, while another
> set only cares about those at 2000 hertz. Armed with this knowledge, the team
> built an algorithm that could decode the words heard based on neural activity
> aloneMovie Camera (PLoS Biology, doi.org/fzv269).
>
> The team hypothesised that hearing speech and thinking to oneself might spark
> some of the same neural signatures in the brain. They supposed that an
> algorithm trained to identify speech heard out loud might also be able to
> identify words that are thought.
>
> Mind-reading
>
> To test the idea, they recorded brain activity in another seven people
> undergoing epilepsy surgery, while they looked at a screen that displayed
> text from either the Gettysburg Address, John F. Kennedy's inaugural address
> or the nursery rhyme Humpty Dumpty.
>
> Each participant was asked to read the text aloud, read it silently in their
> head and then do nothing. While they read the text out loud, the team worked
> out which neurons were reacting to what aspects of speech and generated a
> personalised decoder to interpret this information. The decoder was used to
> create a spectrogram – a visual representation of the different
> frequencies of sound waves heard over time. As each frequency correlates to
> specific sounds in each word spoken, the spectrogram can be used to recreate
> what had been said. They then applied the decoder to the brain activity that
> occurred while the participants read the passages silently to themselves (see
> diagram).
>
> Despite the neural activity from imagined or actual speech differing
> slightly, the decoder was able to reconstruct which words several of the
> volunteers were thinking, using neural activity alone (Frontiers in
> Neuroengineering, doi.org/whb).
>
> The algorithm isn't perfect, says Stephanie Martin, who worked on the study
> with Pasley. "We got significant results but it's not good enough yet to
> build a device."
>
> In practice, if the decoder is to be used by people who are unable to speak
> it would have to be trained on what they hear rather than their own speech.
> "We don't think it would be an issue to train the decoder on heard speech
> because they share overlapping brain areas," says Martin.
>
> The team is now fine-tuning their algorithms, by looking at the neural
> activity associated with speaking rate and different pronunciations of the
> same word, for example. "The bar is very high," says Pasley. "Its preliminary
> data, and we're still working on making it better."
>
> The team have also turned their hand to predicting what songs a person is
> listening to by playing lots of Pink Floyd to volunteers, and then working
> out which neurons respond to what aspects of the music. "Sound is sound,"
> says Pasley. "It all helps us understand different aspects of how the brain
> processes it."
>
> "Ultimately, if we understand covert speech well enough, we'll be able to
> create a medical prosthesis that could help someone who is paralysed, or
> locked in and can't speak," he says.
>
> Several other researchers are also investigating ways to read the human mind.
> Some can tell what pictures a person is looking at, others have worked out
> what neural activity represents certain concepts in the brain, and one team
> has even produced crude reproductions of movie clips that someone is watching
> just by analysing their brain activity. So is it possible to put it all
> together to create one multisensory mind-reading device?
>
> In theory, yes, says Martin, but it would be extraordinarily complicated. She
> says you would need a huge amount of data for each thing you are trying to
> predict. "It would be really interesting to look into. It would allow us to
> predict what people are doing or thinking," she says. "But we need individual
> decoders that work really well before combining different senses."
>
> This article appeared in print under the headline "Hearing our inner voice"


----- End message from Eugen Leitl <eugen@leitl.org> -----




