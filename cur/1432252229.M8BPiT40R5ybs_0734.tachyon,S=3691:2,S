From owner-cypherpunks@al-qaeda.net  Mon Jan 14 13:13:10 2013
Return-Path: <owner-cypherpunks@al-qaeda.net>
Received: from proton.jfet.org (localhost.localdomain [127.0.0.1])
	by proton.jfet.org (8.14.3/8.14.3/Debian-9.4) with ESMTP id r0EIAIhx018431
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NOT)
	for <cypherpunks-outgoing@proton.jfet.org>; Mon, 14 Jan 2013 13:10:18 -0500
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=al-qaeda.net;
	s=cpunks; t=1358187018;
	bh=WZv9B3RHge3lstlLRokBCVXb9VrXZg3NPd0tO6+fzpk=;
	h=Date:From:To:Subject:Message-ID:MIME-Version:Content-Type:Sender;
	b=Of+jh9nZp2Ot91NvNJLa6T6lA/kSVBkVmC4EdtQ/Q6ygQUBnmr4OtUGOv7ih8OgMc
	 3bQ7H30E44KlPfMQIs5uVvAXdBRle0FRR6rD29MwSgFZw12RQXNs1FvlsCaI7gCNua
	 TsfX0iqEL5OM1WtAhkowEK6M50JNrehhlqUySEsE=
Received: (from majordomo@localhost)
	by proton.jfet.org (8.14.3/8.14.3/Submit) id r0EIAIsI018430
	for cypherpunks-outgoing; Mon, 14 Jan 2013 13:10:18 -0500
Date: Mon, 14 Jan 2013 19:10:15 +0100
From: Eugen Leitl <eugen@leitl.org>
To: cypherpunks@al-qaeda.net, info@postbiota.org, zs-p2p@googlegroups.com
Subject: Re: [hackerspaces] Academic scraping
Message-ID: <20130114181015.GH6172@leitl.org>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
User-Agent: Mutt/1.5.18 (2008-05-17)
Sender: owner-cypherpunks@al-qaeda.net
Precedence: bulk
X-Loop: al-qaeda.net
Status: O
Content-Length: 2283
Lines: 59

----- Forwarded message from Bryan Bishop <kanzure@gmail.com> -----

From: Bryan Bishop <kanzure@gmail.com>
Date: Mon, 14 Jan 2013 11:59:38 -0600
To: Lokkju Brennr <lokkju@gmail.com>, Bryan Bishop <kanzure@gmail.com>,
	science-liberation-front@googlegroups.com
Cc: Hackerspaces General Discussion List <discuss@lists.hackerspaces.org>
Subject: Re: [hackerspaces] Academic scraping
Reply-To: science-liberation-front@googlegroups.com

On Mon, Jan 14, 2013 at 11:51 AM, Lokkju Brennr wrote:
> see:
> http://scraperwiki.org
> http://scrapy.org/
>
> Once you have the raw data in a central location, it becomes much easier for
> someone specialized in data processing to convert it to usable form - even
> if it is hard to parse.  It does help to keep the metadata though...

One of my favorite scraping methods at the moment is phantomjs, a
headless wrapper around webkit.

http://phantomjs.org/
https://github.com/ariya/phantomjs
https://github.com/kanzure/pyphantomjs

But for academic projects, I highly recommend zotero's translators.

https://github.com/zotero/translators

Here's why. There's already a huge userbase of zotero users actively
updating these scrapers. When they break, they fix them immediately.
They are all written in javascript and they extract not only the link
to the pdf but also the maximum amount of metadata. With the help of
the zotero/translation-server project, they can be used headlessly.

https://github.com/zotero/translation-server

I have a demo of this working in irc.freenode.net ##hplusroadmap
(paperbot), he just grabs links from our conversation and posts the
pdfs so that we don't have to ask each other for copies.

- Bryan
http://heybryan.org/
1 512 203 0507

-- 
You received this message because you are subscribed to the Google Groups "science-liberation-front" group.
To unsubscribe from this group, send email to science-liberation-front+unsubscribe@googlegroups.com.
For more options, visit https://groups.google.com/groups/opt_out.



----- End forwarded message -----
-- 
Eugen* Leitl <a href="http://leitl.org">leitl</a> http://leitl.org
______________________________________________________________
ICBM: 48.07100, 11.36820 http://www.ativel.com http://postbiota.org
8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE

