From owner-cypherpunks@Algebra.COM  Tue Jan  8 19:03:29 2002
Return-Path: <owner-cypherpunks@Algebra.COM>
Received: from pacific-carrier-annex.mit.edu (PACIFIC-CARRIER-ANNEX.MIT.EDU [18.7.21.83])
	by positron.mit.edu (8.11.6/8.9.3) with ESMTP id g0903TB14353
	for <kwantam@positron.mit.edu>; Tue, 8 Jan 2002 19:03:29 -0500
Received: from ak47.algebra.com (ak47.algebra.com [208.233.99.160])
	by pacific-carrier-annex.mit.edu (8.9.2/8.9.2) with ESMTP id SAA26299
	for <rsw@mit.edu>; Tue, 8 Jan 2002 18:59:57 -0500 (EST)
Received: from ak47.algebra.com (localhost [127.0.0.1])
	by ak47.algebra.com (8.12.1/8.12.1) with ESMTP id g08NMAaA020078
	for <cypherpunks-outgoing@ak47.algebra.com>; Tue, 8 Jan 2002 17:22:10 -0600
Received: (from majordom@localhost)
	by ak47.algebra.com (8.12.1/8.12.1/Submit) id g08NMAi0020077
	for cypherpunks-outgoing; Tue, 8 Jan 2002 17:22:10 -0600
X-Authentication-Warning: ak47.algebra.com: majordom set sender to owner-cypherpunks@Algebra.COM using -f
Received: from slack.lne.com (dns.lne.com [209.157.136.81])
	by ak47.algebra.com (8.12.1/8.12.1) with ESMTP id g08NM5aA020051
	for <cypherpunks@ak47.algebra.com>; Tue, 8 Jan 2002 17:22:07 -0600
Received: (from cpunk@localhost)
	by slack.lne.com (8.11.0/8.11.0) id g08NM2p10066
	for cypherpunks@ak47.algebra.com; Tue, 8 Jan 2002 15:22:02 -0800
Received: (from majordom@localhost)
	by slack.lne.com (8.11.0/8.11.0) id g08NLKQ10041
	for cypherpunks-goingout; Tue, 8 Jan 2002 15:21:20 -0800
X-Authentication-Warning: slack.lne.com: majordom set sender to owner-cypherpunks@lne.com using -f
From: Eric Cordian <emc@artifact.psychedelic.net>
Message-Id: <200201082320.g08NKn509167@artifact.psychedelic.net>
Old-Subject: Re: Random Data Compressed 100:1 (Guffaw)
To: cypherpunks@lne.com
Date: Tue, 8 Jan 2002 15:20:49 -0800 (PST)
In-Reply-To: <3C3B6453.51C97C98@lsil.com> from "Michael Motyka" at Jan
  08, 2002 02:27:47 PM
X-Mailer: ELM [version 2.5 PL3]
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Loop: cypherpunks@lne.com
X-spam: 0 
Subject:  Re: Random Data Compressed 100:1 (Guffaw)
X-Algebra: <A HREF=http://www.algebra.com>Algebra</A>
Sender: owner-cypherpunks@Algebra.COM
Precedence: bulk
X-Mailing-List: cypherpunks@algebra.com
X-List-Admin: ichudov@algebra.com
X-Loop: cypherpunks@algebra.com
X-spam: 0 
Status: O
Content-Length: 3099
Lines: 60


Michael Motyka wrote:

> What exactly is random data? Does it have to appear to be random? 

> Does it have to pass some set of statistical tests to be random? If a
> string or bits from a radiation source spells "Merry Christmas and a
> Happy New Year" in ASCII is it non-random - a message from above?

Randomness is generally defined for sequences, which are mappings from the
non-negative integers onto some finite set of symbols.  A sequence is
random if its values are independently selected and uniformly distributed.

A random sequence of ASCII characters will not only spell out "Merry
Christmas and a Happy New Year" numerous times, but will spell out every
other possible piece of text as well.  In a random sequence of bits, all
2^N N-bit strings are equally likely to occur as we step through the
sequence, for any chosen value of N.

The Theory of Compression works with sequences.  Finite sets of data, or
strings, are considered to be initial segments of sequences.

There is also the notion of the Kolmogorov complexity of a string, which
is the length of the shortest program which generates it.  This also leads
to the Kolmogorov definition of a random string, as one whose shortest
description is itself.

Most practical compression algorithms, however, do not work with the
complexity of data in the Kolmogorov sense, but merely compress a sequence
using a fixed amount of its previous history as a dictionary.

As a simple example of how a good compression algorithm might work,
consider a person sitting in front of a console that displays the first
N-1 characters of some text.  The person tries to guess character N and
makes successive guesses until the computer tells him he is successful.  
If we entropy code the number of guesses at each point, and we presume
different persons use the same deterministic algorithm for guessing based
on a knowlege of the English language, and on what has previously occurred
in the text, we can transform any English text of more than trivial length
into a lesser number of bits than are required to represent it in ASCII.

If we imagine such a scheme applied to the random binary sequence
described earlier, the person will on the average require 1 guess 50% of
the time, and 2 guesses the other 50% of the time to correctly identify
the next bit.  Entropy coding two symbols which occur with equal frequency
requires one bit for each occurrence.  In this case, attempting
"compression" requires one bit output for each bit input, demonstrating
that a random sequence cannot be compressed.

Talking about a finite string being "random" in the commonly accepted
non-Kolmogorov sense is a meaningless notion, apart from the string being
the initial segment of some random seqence.  Any random string is produced
by taking a finite number of instances of some random variable, and such a
random variable has, by definition, an infinite sequence of such instances
over which its mathematical properties are defined.

-- 
Eric Michael Cordian 0+
O:.T:.O:. Mathematical Munitions Division
"Do What Thou Wilt Shall Be The Whole Of The Law"

