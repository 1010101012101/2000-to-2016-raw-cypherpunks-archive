From owner-cypherpunks@lne.com  Wed Dec 10 09:16:32 2003
Return-Path: <owner-cypherpunks@lne.com>
Received: from slack.lne.com (gw.lne.com [209.157.136.81])
	by positron.jfet.org (8.11.6p3/8.11.6-03-31-03) with ESMTP id hBAEGUY19688
	for <rsw@jfet.org>; Wed, 10 Dec 2003 09:16:30 -0500
Received: from slack.lne.com (slack.lne.com [127.0.0.1])
	by slack.lne.com (8.12.10/8.12.10) with ESMTP id hBADwZ9a029149
	(version=TLSv1/SSLv3 cipher=EDH-DSS-DES-CBC3-SHA bits=168 verify=NO)
	for <cypherpunks-goingout345@slack.lne.com>; Wed, 10 Dec 2003 05:58:35 -0800
Received: (from majordom@localhost)
	by slack.lne.com (8.12.10/8.12.10/Submit) id hBADwZ75029148
	for cypherpunks-goingout345; Wed, 10 Dec 2003 05:58:35 -0800
X-Authentication-Warning: slack.lne.com: majordom set sender to owner-cypherpunks@lne.com using -f
Date: Wed, 10 Dec 2003 08:41:37 -0600
From: Declan McCullagh <declan@well.com>
To: cypherpunks@lne.com
Subject: Re: whitehouse.gov/robots.txt
Message-ID: <20031210084137.A754@baltwash.com>
Mail-Followup-To: cypherpunks@lne.com
References: <20031210115624.GN4452@leitl.org>
  <20031210125907.GA19742@pobox.com>
Mime-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
User-Agent: Mutt/1.2.5.1i
In-Reply-To: <20031210125907.GA19742@pobox.com>; from mellon@pobox.com
  on Wed, Dec 10, 2003 at 02:59:07PM +0200
X-URL: http://www.mccullagh.org/
Sender: owner-cypherpunks@lne.com
Precedence: bulk
X-Loop: cypherpunks@lne.com
Status: O
Content-Length: 1127
Lines: 29

This robots.txt issue was exaggerated by leftist crtitics of the
administration. (This is not a general defense of the White House,
just a statement of fact.) The Bush WH.gov server has a special Iraq
section where press releases, speeches, etc. are reposted in a
different HTML template. The WH only wants the "master" copy indexed
and not the duplicate copy in the second template. Hence the apparent
weirdness in robots.txt.

I have not found any skullduggery going on, though I suppose it
wouldn't hurt to keep a copy of the Iraq section for "diff" purposes
just in case.

-Declan


On Wed, Dec 10, 2003 at 02:59:07PM +0200, Anatoly Vorobey wrote:
> On Wed, Dec 10, 2003 at 12:56:24PM +0100, Eugen Leitl wrote:
> > Can somebody with a webspider crawl these documents, and put it up
> > on the web?
> > 
> > 	http://www.whitehouse.gov/robots.txt
> 
> All or nearly all of them are duplicates of same documents
> elsewhere in the directory tree; "X/text/" and "X/iraq/" are
> supposed to be copies of "X/", with images removed in the first 
> case. I suspect that downloading them all would just confirm that.
> 
> --
> avva

