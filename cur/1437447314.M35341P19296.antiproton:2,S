Return-Path: <cypherpunks-bounces@cpunks.org>
Received: from antiproton.jfet.org (localhost.localdomain [127.0.0.1])
	by antiproton.jfet.org (8.14.4/8.14.4/Debian-8) with ESMTP id t6L2sFMP019273;
	Mon, 20 Jul 2015 22:54:20 -0400
Received: from ligemail.lig.net (lig.net [64.69.38.223])
 by antiproton.jfet.org (8.14.4/8.14.4/Debian-8) with ESMTP id t6L2sBtY019269
 (version=TLSv1/SSLv3 cipher=ECDHE-RSA-AES256-SHA bits=256 verify=NOT)
 for <cypherpunks@cpunks.org>; Mon, 20 Jul 2015 22:54:12 -0400
Received: from localhost (localhost [127.0.0.1])
 by ligemail.lig.net (Postfix) with ESMTP id C3D381307DDE
 for <cypherpunks@cpunks.org>; Mon, 20 Jul 2015 19:54:09 -0700 (PDT)
X-Virus-Scanned: Debian amavisd-new at lig.net
Received: from ligemail.lig.net ([127.0.0.1])
 by localhost (lig.lig.net [127.0.0.1]) (amavisd-new, port 10024)
 with ESMTP id BR9KsDxHjwPf for <cypherpunks@cpunks.org>;
 Mon, 20 Jul 2015 19:54:06 -0700 (PDT)
Received: from imac.local (c-73-170-87-105.hsd1.ca.comcast.net [73.170.87.105])
 (using TLSv1.2 with cipher ECDHE-RSA-AES128-GCM-SHA256 (128/128 bits))
 (No client certificate requested) (Authenticated sender: sdw)
 by ligemail.lig.net (Postfix) with ESMTPSA id 009671307DC4
 for <cypherpunks@cpunks.org>; Mon, 20 Jul 2015 19:54:05 -0700 (PDT)
Message-ID: <55ADB44D.5080402@lig.net>
Date: Mon, 20 Jul 2015 19:54:05 -0700
From: "Stephen D. Williams" <sdw@lig.net>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.10;
 rv:31.0) Gecko/20100101 Thunderbird/31.7.0
MIME-Version: 1.0
To: cypherpunks@cpunks.org
Subject: Re: an ominous comment
References: <20150714155203.826F52282E2@palinka.tinho.net>
 <871tg5puda.fsf@mid.deneb.enyo.de> <20150718151551.GA2439@sivokote.iziade.m$>
 <55AA8B5E.1040202@lig.net>
 <CAHWD2rLQFjJ5TR3vZhVrpAcQBd-z88kA5vt9+550uNMS95eYWw@mail.gmail.com>
 <55ad62b8.8915370a.20276.ffffa5a6@mx.google.com> <55AD6DF7.50903@lig.net>
 <CAOsGNSQQWTarFiWLb=CnFicsYsN7W2n90WFa-gF1oLcWwdbfRA@mail.gmail.com>
In-Reply-To: <CAOsGNSQQWTarFiWLb=CnFicsYsN7W2n90WFa-gF1oLcWwdbfRA@mail.gmail.com>
Content-Type: multipart/alternative;
 boundary="------------020600030503050004090807"
X-BeenThere: cypherpunks@cpunks.org
X-Mailman-Version: 2.1.18
Precedence: list
List-Id: The Cypherpunks Mailing List <cypherpunks.cpunks.org>
List-Unsubscribe: <https://cpunks.org/mailman/options/cypherpunks>,
 <mailto:cypherpunks-request@cpunks.org?subject=unsubscribe>
List-Archive: <http://cpunks.org/pipermail/cypherpunks/>
List-Post: <mailto:cypherpunks@cpunks.org>
List-Help: <mailto:cypherpunks-request@cpunks.org?subject=help>
List-Subscribe: <https://cpunks.org/mailman/listinfo/cypherpunks>,
 <mailto:cypherpunks-request@cpunks.org?subject=subscribe>
Errors-To: cypherpunks-bounces@cpunks.org
Sender: "cypherpunks" <cypherpunks-bounces@cpunks.org>
Lines: 740

This is a multi-part message in MIME format.
--------------020600030503050004090807
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 8bit

On 7/20/15 4:56 PM, Zenaan Harkness wrote:
> On 7/20/15, Stephen D. Williams <sdw@lig.net> wrote:
>> On the other hand, life is a balance.
> True. I'm thinking individuals here.
>
>> I probably shouldn't have tried to
>> make the point here, but it is something a security
>> professional should understand well: The right amount of security
>> should be moderated by the tradeoff of costs vs. overhead vs.
>> maximizing benefit vs. minimizing loss.
> Corporations are bound to their economic imperative to make such trade
> offs. This is the heart of their sociopathic nature. This is the part
> of corporations/ companies which needs, somehow, to change in order to
> get this world on a better track.
>
> ...
>> It is terrible that some companies have been too eager to share information.
>>   They may or may not have believed whatever safeguards
>> were in place, or not cared, etc.  I'm sure a high pressure meeting with an
>> FBI crew who are strongly playing the terrorism angle is
>> persuasive, as it should be, up to a point.
> Here's the kind of talk that looks like a hole freshly dug.
>
> Perhaps if there is an actual existential threat to someone's life or
> some building (let's please stop using the T word), then "high
> pressure persuasion" would be adequate for a court order anyway. As it
> should be - up to the point of a subpoena, summons and/ or order to
> perform or act - to handle the actual problem.
>
> You seem though to be normalising behaviours and approaches and "high
> pressure persuasion" tactics by government departments, in a
> generalised way. You might not be intending the things you imply/ say,

You're making an unqualified assumption about my unqualified qualifier "up to a point"...

> but don't be surprised when such positions are mocked or ridiculed.
> Don't take such blow back as personal at all though - it's the
> "normalisation of bad" and "plainly wrong/ evil" which is being
> attacked for the bullshit it is.

Feel free.  I totally mock and rail about it too.  I can see several sides to this, and I've been on enough "sides" of these 
problems, at least in some weak sense, to have some model of decision making by people in those roles.  Poor decisions are 
understandable until there are enough cases, noticed and confronted, to make the right path clear.  We're getting a lot of those 
lately.  EFF, SPLC, ACLU, and others, sometimes including commercial entities, are providing an invaluable service of evolving both 
the law and internal commercial and government policy.

Hacking the system cleverly and deliberately is one of the cooler forms of hacking.

>> And companies holding your data
>> can actually look at that data for business purposes,
> Perhaps try something this instead: "And for-profit therefore
> sociopathic-by-nature companies do massively collect your metadata AND
> your personal information, with or without your consent, and are well
> leaked and reported to use and abuse all your data both within and
> beyond the law, beyond your expectations, and beyond what many people
> consider ethical."

A few quibbles: for-profit is sociopathic-by-default perhaps, although even there you are assuming some socioeconomic system. You're 
also glossing over whether and when consent is an issue. People in public places sometimes believe that others need consent to take 
their picture; generally not true.  Is it rude to take your picture and does rudeness matter?  That depends.  "Beyond your 
expectations" is also problematic: How could any possible expectation ever be said to be adhered to?  Perhaps "generally accepted 
fair use as defined by EFF" or something (if there is such a thing) might be reasonable.  What is the definition of "many people"?

If you use language that can never be satisfied in any reliable way, you can't really complain that an entity isn't satisfying it.

>
> See what we did there? We made it personal, giving a slight hope to
> the uninitiated to realise something they did not realise before. We

Education is always good.  Don't infect others with pathological paranoia, but a healthy understanding of risks and exposures is 
always good.

> highlighted some foundations (for profit being inherently

Not inherently.  Social, economic, legal, contractual, and other cultural systems allow, disallow, guide, and control people in 
their interactions.  The US, for instance, has always been a place where there were many unwritten rules of operating in business.  
Some have run roughshod over those, sometimes reaping unjust rewards and/or changing what is acceptable, but there are always things 
that could be done that just aren't.  Further, a particular entity could impose upon itself, by charter, culture, or customer 
agreement, a more stringent stance than others.  There could be mechanisms that audit or otherwise control this.

You get what you optimize for.  If you have a default corporation controlled by weak, shallow leaders and driven by shallow, blind 
Wall Street numbers, then the result is likely to be sociopathic. On the other hand, however imperfectly or incompletely, certain 
companies have a founder-driven culture of a far more empathic nature than this default, whether they be different or have a stated 
desire to not be evil.  Both of those companies largely care about users in some strong sense, much unlike certain other highly and 
chronically annoying entities.

> sociopathic). We reminded the reader that their consent is often not
> obtained (yes, we can argue about implied consent, the point is we're
> edumacating). We make the assertion that companies actually abuse all
> that data (whatever "abuse" might mean), just in case someone missed
> the memo.

One person's use is another person's abuse.  People should be aware.

>
> With all this, we are also implying that this abuse is wrong.

Abuse is wrong, use may not be.  Sometimes depends on where you stand.  Some types don't have agreement.  Plenty of people hate the 
idea of automated ad filtering based on the content of email or chat or other activity.  There are things that could go wrong with 
that if it gets to a human or is gamed, but properly done anonymously, it can be fine: I'd rather get timely ads I may care about 
than the much larger set of uninteresting dreck.  I actually suggested doing exactly this with AOL chatrooms in about 1996. This is 
a good example of good education vs. bad education: If you say "This could be misused or leaked in a way that could be a problem if 
a company isn't careful, and here is a scenario..., and here is how that could be handled better..." that's fine, especially if a 
company can indicate the level of care & security they're currently employing.  If you say: "Google is reading your email, sending 
it to every company that wants to buy it for a few cents!" that's disingenuous at best and dangerous to certain people's mental 
state at worst.

>
> Your version sounds like you are -trying- to normalise the wrong,
> justify the bad, and 'accept the new messed up world order as best we
> can'. We hear enough of that from others. And I saw NO to that abuse!
> Give me justification for abuse, at your peril!

I was mainly talking about making realistic decisions without a value statement for current practices, which we are all going to 
have different opinions on since they aren't public.

We should have some taxonomy of the nature of those abuses, with consensus lines drawn as to what we all find acceptable or not 
acceptable, why, and what mechanisms best resolve the issue.

>
>
>> although how they use it is somewhat bounded by privacy laws (however
>> incomplete), not making private things public, unfair business
>> practices, etc.  My point was that the existence of large, valuable services
>> that depend on a lot of trust is, or should be to a
> "should be" trustworthy?

Some are not at certain points, or all are not at some points, or only mine is as far as I know.  Take your pick.

> They're companies. You've missed the bloody memo. And a very bloody
> memo the corporate record is, for decades and across industries!

Have you noticed the difference in nature of various companies over time?

>
>> sane entity, an even stronger incentive to behave than the patchwork
>> of laws.
> You're not grokking the incentive. It's profit. And it's more than an
> incentive, profit is the foundational company-constitutional
> imperative for companies (funny that).
>
> This is why companies can NOT be trusted. You seem to be missing this
> basic point. Do you own a company?

Of course; it may not be worth anything, but I do actual work.  You don't?  You're not doing your taxes properly if not...  ;-)

Who CAN be trusted?  At some level, no one, but we've already established that in the real world, you generally have to trust people 
all the time.
Are you sure you are applying your distrust criteria in a comprehensive and rational way?

>> Past oversharing, then embarrassment and public
>> abuse, coupled with product impacts as they lose sensitive customers, has
>> almost certainly caused a cleanup of those attitudes.  I'd
>> be interested in the actual policy right now, although I doubt they are
>> going to be too explicit.  I suspect that it also varies
>> heavily by corporate culture.
> Some companies start with good policy, and good public stance, most
> significantly in this conversation, Google itself - "do no evil". They
> don't say that any more. They can't. Did you ever wonder why they
> stopped saying that?

They pretty much still do.  And it is silly to say they can't.  They are a relatively giant company.  Mistakes happen.  What 
mistakes are they making now?
https://www.google.com/about/company/philosophy/


    You can make money without doing evil.



>
>> Every day, you are somewhat at the mercy of dozens and perhaps thousands
>> of people who could cause you pain, suffering, or death if
>> they were so inclined.  There are many in the government, schools, employer
>> personnel departments, medical and insurance companies,
>> etc.  The people driving around you, stopped at a light while you cross the
>> street, making your food, they all have access and the
>> ability to inflict misery on you.  You have to trust someone to some extent.
> Trust is a relevant foundation to community/ society, sure.
>
> But now you've segued into personal. Which is a good place at times,
> an effective place. It's more tangible for people.
>
> But here we were talking about companies. I would ordinarily presume
> your trust formula is different for companies that it is for actual,
> you know, humans.
>
> I suggest not overloading corporate rights, corporate trust, with
> human rights, human trust. Not particularly useful in our context.

All companies that I know about are filled with people.  They may be sheeple a little too often (I have permanently fired ATT Mobile 
(formerly Cingular) for refusing to issue a refund to my son when they screwed up "because the policy prevents us".), but it is 
personal at some level.  You are trusting that the Comcast installer is not a murderer, that the banker isn't stealing from you, and 
that the well-paid Google engineer has better things to do than to eavesdrop on you.

>> The question is who you trust, how incentivized they
>> and the people / organization around them protects you, whether wrongs will
>> be limited, corrected, and righted or not.
> A rational approach is warranted for sure.
>
> Companies, and in most cases humans working for them, are
> predominantly incentivized by money. Yesterday I read an article on

Whether all are, or even a predominant amount are, is questionable. Many people care about customers, their career, mission, etc.  
Money is only an issue occasionally.

> the Great Wall of China. Incredible vision, so many centuries of
> building. But when it came down to the time it was 'needed', due to
> there being only so many sentries, and so far spread out, and the
> sentries paid so little, when the marauding Mongols wanted in, to do
> some marauding, they just bribed a sentry or two. Apparently same with
> the Europeans in more recent times. So, incentivized people were,
> secure, wall was not. The biggest security theater.
>
> I think the great wall may have been useful psychologically though...
> to encourage a mindset of unity in the people within.
>
>
>> For a long time, as a contractor at the peak of their heyday, I had access
>> to AOL's entire user database, complete with name,
>> address, full credit card info, phone numbers, etc.  I could have also
>> snooped on their Buddylists, their person-to-person video
>> (Instant Images), and a lot more.  There was zero chance that I would abuse
>> any of that.
> Your ethics are admirable. I share your personal intentions. I don't
> trust companies though, except to plunder markets to the maximum
> profit possible.

There are some who have acted that way, for sure.  I have my black list.  Others try.  They deserve a little credit, and help when 
possible.

>
> Zenaan
>
>> sdw

sdw

>>
>> On 7/20/15 2:07 PM, Juan wrote:
>>> 	cypherpunk :
>>>
>>> 	https://www.wikileaks.org/Op-ed-Google-and-the-NSA-Who-s.html
>>>
>>> 	"Google and the NSA: Who’s holding the ‘shit-bag’ now?"
>>>
>>>
>>> 	Not-cypherpunk-at-all :
>>>
>>>
>>>> 2015-07-19 2:22 GMT+09:00 Stephen D. Williams <sdw@lig.net>:
>>>>
>>>> I feel perfectly confident that Google is going to protect their
>>>> billions in income and valuation by being very careful with
>>>> avoiding abusing their data or users in any strong sense.


-- 
Stephen D. Williams sdw@lig.net stephendwilliams@gmail.com LinkedIn: http://sdw.st/in
V:650-450-UNIX (8649) V:866.SDW.UNIX V:703.371.9362 F:703.995.0407
AIM:sdw Skype:StephenDWilliams Yahoo:sdwlignet Resume: http://sdw.st/gres
Personal: http://sdw.st facebook.com/sdwlig twitter.com/scienteer


--------------020600030503050004090807
Content-Type: text/html; charset=utf-8
Content-Transfer-Encoding: 8bit

<html>
  <head>
    <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
  </head>
  <body bgcolor="#FFFFFF" text="#000066">
    <div class="moz-cite-prefix">On 7/20/15 4:56 PM, Zenaan Harkness
      wrote:<br>
    </div>
    <blockquote
cite="mid:CAOsGNSQQWTarFiWLb=CnFicsYsN7W2n90WFa-gF1oLcWwdbfRA@mail.gmail.com"
      type="cite">
      <pre wrap="">On 7/20/15, Stephen D. Williams <a class="moz-txt-link-rfc2396E" href="mailto:sdw@lig.net">&lt;sdw@lig.net&gt;</a> wrote:
</pre>
      <blockquote type="cite">
        <pre wrap="">On the other hand, life is a balance.
</pre>
      </blockquote>
      <pre wrap="">
True. I'm thinking individuals here.

</pre>
      <blockquote type="cite">
        <pre wrap="">I probably shouldn't have tried to
make the point here, but it is something a security
professional should understand well: The right amount of security
should be moderated by the tradeoff of costs vs. overhead vs.
maximizing benefit vs. minimizing loss.
</pre>
      </blockquote>
      <pre wrap="">
Corporations are bound to their economic imperative to make such trade
offs. This is the heart of their sociopathic nature. This is the part
of corporations/ companies which needs, somehow, to change in order to
get this world on a better track.

...
</pre>
      <blockquote type="cite">
        <pre wrap="">It is terrible that some companies have been too eager to share information.
 They may or may not have believed whatever safeguards
were in place, or not cared, etc.  I'm sure a high pressure meeting with an
FBI crew who are strongly playing the terrorism angle is
persuasive, as it should be, up to a point.
</pre>
      </blockquote>
      <pre wrap="">
Here's the kind of talk that looks like a hole freshly dug.

Perhaps if there is an actual existential threat to someone's life or
some building (let's please stop using the T word), then "high
pressure persuasion" would be adequate for a court order anyway. As it
should be - up to the point of a subpoena, summons and/ or order to
perform or act - to handle the actual problem.

You seem though to be normalising behaviours and approaches and "high
pressure persuasion" tactics by government departments, in a
generalised way. You might not be intending the things you imply/ say,</pre>
    </blockquote>
    <br>
    You're making an unqualified assumption about my unqualified
    qualifier "up to a point"...<br>
    <br>
    <blockquote
cite="mid:CAOsGNSQQWTarFiWLb=CnFicsYsN7W2n90WFa-gF1oLcWwdbfRA@mail.gmail.com"
      type="cite">
      <pre wrap="">
but don't be surprised when such positions are mocked or ridiculed.
Don't take such blow back as personal at all though - it's the
"normalisation of bad" and "plainly wrong/ evil" which is being
attacked for the bullshit it is.</pre>
    </blockquote>
    <br>
    Feel free.  I totally mock and rail about it too.  I can see several
    sides to this, and I've been on enough "sides" of these problems, at
    least in some weak sense, to have some model of decision making by
    people in those roles.  Poor decisions are understandable until
    there are enough cases, noticed and confronted, to make the right
    path clear.  We're getting a lot of those lately.  EFF, SPLC, ACLU,
    and others, sometimes including commercial entities, are providing
    an invaluable service of evolving both the law and internal
    commercial and government policy.<br>
    <br>
    Hacking the system cleverly and deliberately is one of the cooler
    forms of hacking.<br>
    <br>
    <blockquote
cite="mid:CAOsGNSQQWTarFiWLb=CnFicsYsN7W2n90WFa-gF1oLcWwdbfRA@mail.gmail.com"
      type="cite">
      <pre wrap="">
</pre>
      <blockquote type="cite">
        <pre wrap="">And companies holding your data
can actually look at that data for business purposes,
</pre>
      </blockquote>
      <pre wrap="">
Perhaps try something this instead: "And for-profit therefore
sociopathic-by-nature companies do massively collect your metadata AND
your personal information, with or without your consent, and are well
leaked and reported to use and abuse all your data both within and
beyond the law, beyond your expectations, and beyond what many people
consider ethical."</pre>
    </blockquote>
    <br>
    A few quibbles: for-profit is sociopathic-by-default perhaps,
    although even there you are assuming some socioeconomic system. 
    You're also glossing over whether and when consent is an issue. 
    People in public places sometimes believe that others need consent
    to take their picture; generally not true.  Is it rude to take your
    picture and does rudeness matter?  That depends.  "Beyond your
    expectations" is also problematic: How could any possible
    expectation ever be said to be adhered to?  Perhaps "generally
    accepted fair use as defined by EFF" or something (if there is such
    a thing) might be reasonable.  What is the definition of "many
    people"?<br>
    <br>
    If you use language that can never be satisfied in any reliable way,
    you can't really complain that an entity isn't satisfying it.<br>
    <br>
    <blockquote
cite="mid:CAOsGNSQQWTarFiWLb=CnFicsYsN7W2n90WFa-gF1oLcWwdbfRA@mail.gmail.com"
      type="cite">
      <pre wrap="">

See what we did there? We made it personal, giving a slight hope to
the uninitiated to realise something they did not realise before. We</pre>
    </blockquote>
    <br>
    Education is always good.  Don't infect others with pathological
    paranoia, but a healthy understanding of risks and exposures is
    always good.<br>
    <br>
    <blockquote
cite="mid:CAOsGNSQQWTarFiWLb=CnFicsYsN7W2n90WFa-gF1oLcWwdbfRA@mail.gmail.com"
      type="cite">
      <pre wrap="">
highlighted some foundations (for profit being inherently</pre>
    </blockquote>
    <br>
    Not inherently.  Social, economic, legal, contractual, and other
    cultural systems allow, disallow, guide, and control people in their
    interactions.  The US, for instance, has always been a place where
    there were many unwritten rules of operating in business.  Some have
    run roughshod over those, sometimes reaping unjust rewards and/or
    changing what is acceptable, but there are always things that could
    be done that just aren't.  Further, a particular entity could impose
    upon itself, by charter, culture, or customer agreement, a more
    stringent stance than others.  There could be mechanisms that audit
    or otherwise control this.<br>
    <br>
    You get what you optimize for.  If you have a default corporation
    controlled by weak, shallow leaders and driven by shallow, blind
    Wall Street numbers, then the result is likely to be sociopathic. 
    On the other hand, however imperfectly or incompletely, certain
    companies have a founder-driven culture of a far more empathic
    nature than this default, whether they be different or have a stated
    desire to not be evil.  Both of those companies largely care about
    users in some strong sense, much unlike certain other highly and
    chronically annoying entities.<br>
    <br>
    <blockquote
cite="mid:CAOsGNSQQWTarFiWLb=CnFicsYsN7W2n90WFa-gF1oLcWwdbfRA@mail.gmail.com"
      type="cite">
      <pre wrap="">
sociopathic). We reminded the reader that their consent is often not
obtained (yes, we can argue about implied consent, the point is we're
edumacating). We make the assertion that companies actually abuse all
that data (whatever "abuse" might mean), just in case someone missed
the memo.</pre>
    </blockquote>
    <br>
    One person's use is another person's abuse.  People should be aware.<br>
    <br>
    <blockquote
cite="mid:CAOsGNSQQWTarFiWLb=CnFicsYsN7W2n90WFa-gF1oLcWwdbfRA@mail.gmail.com"
      type="cite">
      <pre wrap="">

With all this, we are also implying that this abuse is wrong.</pre>
    </blockquote>
    <br>
    Abuse is wrong, use may not be.  Sometimes depends on where you
    stand.  Some types don't have agreement.  Plenty of people hate the
    idea of automated ad filtering based on the content of email or chat
    or other activity.  There are things that could go wrong with that
    if it gets to a human or is gamed, but properly done anonymously, it
    can be fine: I'd rather get timely ads I may care about than the
    much larger set of uninteresting dreck.  I actually suggested doing
    exactly this with AOL chatrooms in about 1996. This is a good
    example of good education vs. bad education: If you say "This could
    be misused or leaked in a way that could be a problem if a company
    isn't careful, and here is a scenario..., and here is how that could
    be handled better..." that's fine, especially if a company can
    indicate the level of care &amp; security they're currently
    employing.  If you say: "Google is reading your email, sending it to
    every company that wants to buy it for a few cents!" that's
    disingenuous at best and dangerous to certain people's mental state
    at worst.<br>
    <br>
    <blockquote
cite="mid:CAOsGNSQQWTarFiWLb=CnFicsYsN7W2n90WFa-gF1oLcWwdbfRA@mail.gmail.com"
      type="cite">
      <pre wrap="">

Your version sounds like you are -trying- to normalise the wrong,
justify the bad, and 'accept the new messed up world order as best we
can'. We hear enough of that from others. And I saw NO to that abuse!
Give me justification for abuse, at your peril!</pre>
    </blockquote>
    <br>
    I was mainly talking about making realistic decisions without a
    value statement for current practices, which we are all going to
    have different opinions on since they aren't public.<br>
    <br>
    We should have some taxonomy of the nature of those abuses, with
    consensus lines drawn as to what we all find acceptable or not
    acceptable, why, and what mechanisms best resolve the issue.<br>
    <br>
    <blockquote
cite="mid:CAOsGNSQQWTarFiWLb=CnFicsYsN7W2n90WFa-gF1oLcWwdbfRA@mail.gmail.com"
      type="cite">
      <pre wrap="">


</pre>
      <blockquote type="cite">
        <pre wrap="">although how they use it is somewhat bounded by privacy laws (however
incomplete), not making private things public, unfair business
practices, etc.  My point was that the existence of large, valuable services
that depend on a lot of trust is, or should be to a
</pre>
      </blockquote>
      <pre wrap="">
"should be" trustworthy?</pre>
    </blockquote>
    <br>
    Some are not at certain points, or all are not at some points, or
    only mine is as far as I know.  Take your pick.<br>
    <br>
    <blockquote
cite="mid:CAOsGNSQQWTarFiWLb=CnFicsYsN7W2n90WFa-gF1oLcWwdbfRA@mail.gmail.com"
      type="cite">
      <pre wrap="">
They're companies. You've missed the bloody memo. And a very bloody
memo the corporate record is, for decades and across industries!</pre>
    </blockquote>
    <br>
    Have you noticed the difference in nature of various companies over
    time?<br>
    <br>
    <blockquote
cite="mid:CAOsGNSQQWTarFiWLb=CnFicsYsN7W2n90WFa-gF1oLcWwdbfRA@mail.gmail.com"
      type="cite">
      <pre wrap="">

</pre>
      <blockquote type="cite">
        <pre wrap="">sane entity, an even stronger incentive to behave than the patchwork
of laws.
</pre>
      </blockquote>
      <pre wrap="">
You're not grokking the incentive. It's profit. And it's more than an
incentive, profit is the foundational company-constitutional
imperative for companies (funny that).

This is why companies can NOT be trusted. You seem to be missing this
basic point. Do you own a company?</pre>
    </blockquote>
    <br>
    Of course; it may not be worth anything, but I do actual work.  You
    don't?  You're not doing your taxes properly if not...  ;-)<br>
    <br>
    Who CAN be trusted?  At some level, no one, but we've already
    established that in the real world, you generally have to trust
    people all the time.<br>
    Are you sure you are applying your distrust criteria in a
    comprehensive and rational way?<br>
    <br>
    <blockquote
cite="mid:CAOsGNSQQWTarFiWLb=CnFicsYsN7W2n90WFa-gF1oLcWwdbfRA@mail.gmail.com"
      type="cite">
      <pre wrap="">
</pre>
      <blockquote type="cite">
        <pre wrap="">Past oversharing, then embarrassment and public
abuse, coupled with product impacts as they lose sensitive customers, has
almost certainly caused a cleanup of those attitudes.  I'd
be interested in the actual policy right now, although I doubt they are
going to be too explicit.  I suspect that it also varies
heavily by corporate culture.
</pre>
      </blockquote>
      <pre wrap="">
Some companies start with good policy, and good public stance, most
significantly in this conversation, Google itself - "do no evil". They
don't say that any more. They can't. Did you ever wonder why they
stopped saying that?
</pre>
    </blockquote>
    <br>
    They pretty much still do.  And it is silly to say they can't.  They
    are a relatively giant company.  Mistakes happen.  What mistakes are
    they making now?<br>
    <a class="moz-txt-link-freetext" href="https://www.google.com/about/company/philosophy/">https://www.google.com/about/company/philosophy/</a><br>
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <h2>You can make money without doing evil. </h2>
    <br>
    <br>
    <blockquote
cite="mid:CAOsGNSQQWTarFiWLb=CnFicsYsN7W2n90WFa-gF1oLcWwdbfRA@mail.gmail.com"
      type="cite">
      <pre wrap="">

</pre>
      <blockquote type="cite">
        <pre wrap="">Every day, you are somewhat at the mercy of dozens and perhaps thousands
of people who could cause you pain, suffering, or death if
they were so inclined.  There are many in the government, schools, employer
personnel departments, medical and insurance companies,
etc.  The people driving around you, stopped at a light while you cross the
street, making your food, they all have access and the
ability to inflict misery on you.  You have to trust someone to some extent.
</pre>
      </blockquote>
      <pre wrap="">
Trust is a relevant foundation to community/ society, sure.

But now you've segued into personal. Which is a good place at times,
an effective place. It's more tangible for people.

But here we were talking about companies. I would ordinarily presume
your trust formula is different for companies that it is for actual,
you know, humans.

I suggest not overloading corporate rights, corporate trust, with
human rights, human trust. Not particularly useful in our context.</pre>
    </blockquote>
    <br>
    All companies that I know about are filled with people.  They may be
    sheeple a little too often (I have permanently fired ATT Mobile
    (formerly Cingular) for refusing to issue a refund to my son when
    they screwed up "because the policy prevents us".), but it is
    personal at some level.  You are trusting that the Comcast installer
    is not a murderer, that the banker isn't stealing from you, and that
    the well-paid Google engineer has better things to do than to
    eavesdrop on you.<br>
    <br>
    <blockquote
cite="mid:CAOsGNSQQWTarFiWLb=CnFicsYsN7W2n90WFa-gF1oLcWwdbfRA@mail.gmail.com"
      type="cite">
      <pre wrap="">
</pre>
      <blockquote type="cite">
        <pre wrap="">The question is who you trust, how incentivized they
and the people / organization around them protects you, whether wrongs will
be limited, corrected, and righted or not.
</pre>
      </blockquote>
      <pre wrap="">
A rational approach is warranted for sure.

Companies, and in most cases humans working for them, are
predominantly incentivized by money. Yesterday I read an article on</pre>
    </blockquote>
    <br>
    Whether all are, or even a predominant amount are, is questionable. 
    Many people care about customers, their career, mission, etc.  Money
    is only an issue occasionally.<br>
    <br>
    <blockquote
cite="mid:CAOsGNSQQWTarFiWLb=CnFicsYsN7W2n90WFa-gF1oLcWwdbfRA@mail.gmail.com"
      type="cite">
      <pre wrap="">
the Great Wall of China. Incredible vision, so many centuries of
building. But when it came down to the time it was 'needed', due to
there being only so many sentries, and so far spread out, and the
sentries paid so little, when the marauding Mongols wanted in, to do
some marauding, they just bribed a sentry or two. Apparently same with
the Europeans in more recent times. So, incentivized people were,
secure, wall was not. The biggest security theater.

I think the great wall may have been useful psychologically though...
to encourage a mindset of unity in the people within.


</pre>
      <blockquote type="cite">
        <pre wrap="">For a long time, as a contractor at the peak of their heyday, I had access
to AOL's entire user database, complete with name,
address, full credit card info, phone numbers, etc.  I could have also
snooped on their Buddylists, their person-to-person video
(Instant Images), and a lot more.  There was zero chance that I would abuse
any of that.
</pre>
      </blockquote>
      <pre wrap="">
Your ethics are admirable. I share your personal intentions. I don't
trust companies though, except to plunder markets to the maximum
profit possible.</pre>
    </blockquote>
    <br>
    There are some who have acted that way, for sure.  I have my black
    list.  Others try.  They deserve a little credit, and help when
    possible.<br>
    <br>
    <blockquote
cite="mid:CAOsGNSQQWTarFiWLb=CnFicsYsN7W2n90WFa-gF1oLcWwdbfRA@mail.gmail.com"
      type="cite">
      <pre wrap="">

Zenaan

</pre>
      <blockquote type="cite">
        <pre wrap="">sdw</pre>
      </blockquote>
    </blockquote>
    <br>
    sdw<br>
    <br>
    <blockquote
cite="mid:CAOsGNSQQWTarFiWLb=CnFicsYsN7W2n90WFa-gF1oLcWwdbfRA@mail.gmail.com"
      type="cite">
      <blockquote type="cite">
        <pre wrap="">

On 7/20/15 2:07 PM, Juan wrote:
</pre>
        <blockquote type="cite">
          <pre wrap="">
	cypherpunk :

	<a class="moz-txt-link-freetext" href="https://www.wikileaks.org/Op-ed-Google-and-the-NSA-Who-s.html">https://www.wikileaks.org/Op-ed-Google-and-the-NSA-Who-s.html</a>

	"Google and the NSA: Who’s holding the ‘shit-bag’ now?"


	Not-cypherpunk-at-all :


</pre>
          <blockquote type="cite">
            <pre wrap="">2015-07-19 2:22 GMT+09:00 Stephen D. Williams <a class="moz-txt-link-rfc2396E" href="mailto:sdw@lig.net">&lt;sdw@lig.net&gt;</a>:

I feel perfectly confident that Google is going to protect their
billions in income and valuation by being very careful with
avoiding abusing their data or users in any strong sense.
</pre>
          </blockquote>
        </blockquote>
      </blockquote>
    </blockquote>
    <br>
    <br>
    <pre class="moz-signature" cols="132">-- 
Stephen D. Williams <a class="moz-txt-link-abbreviated" href="mailto:sdw@lig.net">sdw@lig.net</a> <a class="moz-txt-link-abbreviated" href="mailto:stephendwilliams@gmail.com">stephendwilliams@gmail.com</a> LinkedIn: <a class="moz-txt-link-freetext" href="http://sdw.st/in">http://sdw.st/in</a>
V:650-450-UNIX (8649) V:866.SDW.UNIX V:703.371.9362 F:703.995.0407
<a class="moz-txt-link-freetext" href="AIM:sdw">AIM:sdw</a> <a class="moz-txt-link-freetext" href="Skype:StephenDWilliams">Skype:StephenDWilliams</a> <a class="moz-txt-link-freetext" href="Yahoo:sdwlignet">Yahoo:sdwlignet</a> Resume: <a class="moz-txt-link-freetext" href="http://sdw.st/gres">http://sdw.st/gres</a>
Personal: <a class="moz-txt-link-freetext" href="http://sdw.st">http://sdw.st</a> facebook.com/sdwlig twitter.com/scienteer
</pre>
  </body>
</html>

--------------020600030503050004090807--

