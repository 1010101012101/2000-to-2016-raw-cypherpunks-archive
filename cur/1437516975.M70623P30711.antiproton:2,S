Return-Path: <cypherpunks-bounces@cpunks.org>
Received: from antiproton.jfet.org (localhost.localdomain [127.0.0.1])
	by antiproton.jfet.org (8.14.4/8.14.4/Debian-8) with ESMTP id t6LMEvdN030667;
	Tue, 21 Jul 2015 18:15:03 -0400
Received: from ligemail.lig.net (lig.net [64.69.38.223])
 by antiproton.jfet.org (8.14.4/8.14.4/Debian-8) with ESMTP id t6LMErAH030663
 (version=TLSv1/SSLv3 cipher=ECDHE-RSA-AES256-SHA bits=256 verify=NOT)
 for <cypherpunks@cpunks.org>; Tue, 21 Jul 2015 18:14:54 -0400
Received: from localhost (localhost [127.0.0.1])
 by ligemail.lig.net (Postfix) with ESMTP id 5BA2D130FE2C;
 Tue, 21 Jul 2015 15:14:53 -0700 (PDT)
X-Virus-Scanned: Debian amavisd-new at lig.net
Received: from ligemail.lig.net ([127.0.0.1])
 by localhost (lig.lig.net [127.0.0.1]) (amavisd-new, port 10024)
 with ESMTP id IbIszmXUESdD; Tue, 21 Jul 2015 15:14:50 -0700 (PDT)
Received: from imac.local (c-73-170-87-105.hsd1.ca.comcast.net [73.170.87.105])
 (using TLSv1.2 with cipher ECDHE-RSA-AES128-GCM-SHA256 (128/128 bits))
 (No client certificate requested) (Authenticated sender: sdw)
 by ligemail.lig.net (Postfix) with ESMTPSA id 4C685130FE16;
 Tue, 21 Jul 2015 15:14:50 -0700 (PDT)
Message-ID: <55AEC459.8000600@lig.net>
Date: Tue, 21 Jul 2015 15:14:49 -0700
From: "Stephen D. Williams" <sdw@lig.net>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.10;
 rv:31.0) Gecko/20100101 Thunderbird/31.7.0
MIME-Version: 1.0
To: dan@geer.org, cypherpunks@cpunks.org
Subject: Re: an ominous comment
References: <20150721180105.491862280EA@palinka.tinho.net>
In-Reply-To: <20150721180105.491862280EA@palinka.tinho.net>
Content-Type: multipart/alternative;
 boundary="------------040608010204040907060506"
X-BeenThere: cypherpunks@cpunks.org
X-Mailman-Version: 2.1.18
Precedence: list
List-Id: The Cypherpunks Mailing List <cypherpunks.cpunks.org>
List-Unsubscribe: <https://cpunks.org/mailman/options/cypherpunks>,
 <mailto:cypherpunks-request@cpunks.org?subject=unsubscribe>
List-Archive: <http://cpunks.org/pipermail/cypherpunks/>
List-Post: <mailto:cypherpunks@cpunks.org>
List-Help: <mailto:cypherpunks-request@cpunks.org?subject=help>
List-Subscribe: <https://cpunks.org/mailman/listinfo/cypherpunks>,
 <mailto:cypherpunks-request@cpunks.org?subject=subscribe>
Errors-To: cypherpunks-bounces@cpunks.org
Sender: "cypherpunks" <cypherpunks-bounces@cpunks.org>
Lines: 125

This is a multi-part message in MIME format.
--------------040608010204040907060506
Content-Type: text/plain; charset=windows-1252; format=flowed
Content-Transfer-Encoding: 7bit

On 7/21/15 11:01 AM, dan@geer.org wrote:
> Continuing to think about this, an analogy presents itself.
> If I tell you a secret after getting your agreement that you
> will not yourself tell anyone else, then I am trusting in
> non-recursive disclosure, i.e., you break the chain and I
> trust that you will not fail to do so.
>
> If I place my execution or my storage in the hands of
> others, then I am trusting in non-recursive propagation of
> my code and/or my data.  If the pinnacle goal of security
> engineering is "No silent failure," then creating a
> dependence on non-recursive exposure of execution or storage
> is resolved either by blind trust or by a sufficient degree
> of surveillability that prevents silent breaking of the
> non-recursion constraint.  But what would that be?  Is this
> a kind of supply chain argument that devolves to whether a
> target is or is not big enough to sue?  If I have proven,
> workable recourse, then perhaps I can trust -- which is to
> say I am able to then choose to take no additional,
> proactive countermeasures.  If I do not have proven,
> workable recourse, then how can I prevent not just silent
> failure but silent failure plus a clean getaway even
> post-discovery?
>
> Daniel Solove suggested that the greatest danger to privacy
> is a blythe "I live a good life and have nothing to hide;"
> so, in parallel, is not the greatest danger to data
> integrity something of a parallel construction, something
> like "No one would want to screw with my cloud, I'm just a
> nobody"?
>
> Thinking out loud; no need to answer,
>
> --dan
+1

There are multiple avenues possible of assurance, architecture, audit, obfuscation, canaries, etc.  Perhaps encrypted computing will 
be useful; already encrypted storage is relatively easy to use for at least some circumstances (object stores, backup).  If billions 
of lightweight container-based compute transactions are flowing through a system that pools payment and has secure distributed 
storage and communication, is it possible to be too obscure to identify and tap?

Spammer scammers are practicing this kind of thing daily, and countermeasures are being created too, but as for most of that there 
is a final traceable step, email etc., that's not quite the same as some other private security goals.

sdw


--------------040608010204040907060506
Content-Type: text/html; charset=windows-1252
Content-Transfer-Encoding: 8bit

<html>
  <head>
    <meta content="text/html; charset=windows-1252"
      http-equiv="Content-Type">
  </head>
  <body bgcolor="#FFFFFF" text="#000066">
    <div class="moz-cite-prefix">On 7/21/15 11:01 AM, <a class="moz-txt-link-abbreviated" href="mailto:dan@geer.org">dan@geer.org</a>
      wrote:<br>
    </div>
    <blockquote cite="mid:20150721180105.491862280EA@palinka.tinho.net"
      type="cite">
      <pre wrap="">Continuing to think about this, an analogy presents itself.
If I tell you a secret after getting your agreement that you
will not yourself tell anyone else, then I am trusting in
non-recursive disclosure, i.e., you break the chain and I
trust that you will not fail to do so.

If I place my execution or my storage in the hands of
others, then I am trusting in non-recursive propagation of
my code and/or my data.  If the pinnacle goal of security
engineering is "No silent failure," then creating a
dependence on non-recursive exposure of execution or storage
is resolved either by blind trust or by a sufficient degree
of surveillability that prevents silent breaking of the
non-recursion constraint.  But what would that be?  Is this
a kind of supply chain argument that devolves to whether a
target is or is not big enough to sue?  If I have proven,
workable recourse, then perhaps I can trust -- which is to
say I am able to then choose to take no additional,
proactive countermeasures.  If I do not have proven,
workable recourse, then how can I prevent not just silent
failure but silent failure plus a clean getaway even
post-discovery?

Daniel Solove suggested that the greatest danger to privacy
is a blythe "I live a good life and have nothing to hide;"
so, in parallel, is not the greatest danger to data
integrity something of a parallel construction, something
like "No one would want to screw with my cloud, I'm just a
nobody"?

Thinking out loud; no need to answer,

--dan
</pre>
    </blockquote>
    +1<br>
    <br>
    There are multiple avenues possible of assurance, architecture,
    audit, obfuscation, canaries, etc.  Perhaps encrypted computing will
    be useful; already encrypted storage is relatively easy to use for
    at least some circumstances (object stores, backup).  If billions of
    lightweight container-based compute transactions are flowing through
    a system that pools payment and has secure distributed storage and
    communication, is it possible to be too obscure to identify and tap?<br>
    <br>
    Spammer scammers are practicing this kind of thing daily, and
    countermeasures are being created too, but as for most of that there
    is a final traceable step, email etc., that's not quite the same as
    some other private security goals.<br>
    <br>
    sdw<br>
    <br>
  </body>
</html>

--------------040608010204040907060506--

